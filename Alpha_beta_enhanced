import copy

# Game constants
EMPTY = '-'
PLAYER_X = 'X'
PLAYER_O = 'O'
ROWS = 6
COLS = 7

# Initialize the board
def create_board():
    return [[EMPTY] * COLS for _ in range(ROWS)]

# Check if a player has won the game
def has_won(board, player):
    # Check rows
    for row in board:
        for col in range(COLS - 3):
            if row[col] == row[col+1] == row[col+2] == row[col+3] == player:
                return True

    # Check columns
    for col in range(COLS):
        for row in range(ROWS - 3):
            if board[row][col] == board[row+1][col] == board[row+2][col] == board[row+3][col] == player:
                return True

    # Check diagonals
    for row in range(ROWS - 3):
        for col in range(COLS - 3):
            if board[row][col] == board[row+1][col+1] == board[row+2][col+2] == board[row+3][col+3] == player:
                return True
            if board[row+3][col] == board[row+2][col+1] == board[row+1][col+2] == board[row][col+3] == player:
                return True

    return False

# Check if the board is full
def is_board_full(board):
    for row in board:
        if EMPTY in row:
            return False
    return True

# Print the board
def print_board(board):
    for row in board:
        print(' '.join(row))
    print()

# Get all possible actions (valid moves) for the current state
def get_possible_actions(board):
    actions = []
    for col in range(COLS):
        if board[0][col] == EMPTY:
            actions.append(col)
    return actions

# Make a move in the board
def make_move(board, action, player):
    for row in range(ROWS-1, -1, -1):
        if board[row][action] == EMPTY:
            board[row][action] = player
            break

# Minimax algorithm with Alpha-Beta pruning
def minimax(board, depth, alpha, beta, maximizing_player):
    if depth == 0 or has_won(board, PLAYER_X) or has_won(board, PLAYER_O) or is_board_full(board):
        # Calculate the score for the leaf node
        if has_won(board, PLAYER_X):
            return 1
        elif has_won(board, PLAYER_O):
            return -1
        else:
            return 0

    if maximizing_player:
        max_eval = float('-inf')
        for action in get_possible_actions(board):
            new_board = copy.deepcopy(board)
            make_move(new_board, action, PLAYER_X)
            eval = minimax(new_board, depth - 1, alpha, beta, False)
            max_eval = max(max_eval, eval)
            alpha = max(alpha, eval)
            if beta <= alpha:
                break
        return max_eval
    else:
        min_eval = float('inf')
        for action in get_possible_actions(board):
            new_board = copy.deepcopy(board)
            make_move(new_board, action, PLAYER_O)
            eval = minimax(new_board, depth - 1, alpha, beta, True)
            min_eval = min(min_eval, eval)
            beta = min(beta, eval)
            if beta <= alpha:
                break
        return min_eval

        # Find the best move for the AI agent using Minimax with Alpha-Beta pruning
def alphabeta(board, depth, alpha, beta, maximizing_player):
    if depth == 0 or has_won(board, PLAYER_X) or has_won(board, PLAYER_O) or is_board_full(board):
        if has_won(board, PLAYER_X):
            return 100
        elif has_won(board, PLAYER_O):
            return -100
        else:
            return 0

    if maximizing_player:
        max_eval = float('-inf')
        for action in get_possible_actions(board):
            new_board = copy.deepcopy(board)
            make_move(new_board, action, PLAYER_X)
            eval = alphabeta(new_board, depth - 1, alpha, beta, False)
            max_eval = max(max_eval, eval)
            alpha = max(alpha, eval)
            if beta <= alpha:
                break
        return max_eval
    else:
        min_eval = float('inf')
        for action in get_possible_actions(board):
            new_board = copy.deepcopy(board)
            make_move(new_board, action, PLAYER_O)
            eval = alphabeta(new_board, depth - 1, alpha, beta, True)
            min_eval = min(min_eval, eval)
            beta = min(beta, eval)
            if beta <= alpha:
                break
        return min_eval
def find_best_move(board):
    best_move = None
    best_eval = float('-inf')
    alpha = float('-inf')
    beta = float('inf')
    depth = 6  # Adjust the depth here

    for action in get_possible_actions(board):
        new_board = copy.deepcopy(board)
        make_move(new_board, action, PLAYER_X)
        eval = alphabeta(new_board, depth, alpha, beta, False)
        
        if eval > best_eval:
            best_eval = eval
            best_move = action

    return best_move
# Main game loop
def play_game():
    board = create_board()
    current_player = PLAYER_X

    while True:
        print_board(board)

        if current_player == PLAYER_X:
            # Human's turn
            valid_input = False
            while not valid_input:
                column = input("Your turn (0-6): ")
                if column.isdigit():
                    column = int(column)
                    if column in get_possible_actions(board):
                        valid_input = True
                    else:
                        print("Invalid column. Try again.")
                else:
                    print("Invalid input. Try again.")

            make_move(board, column, current_player)
        else:
            # AI agent's turn
            column = find_best_move(board)
            make_move(board, column, current_player)

        if has_won(board, current_player):
            print_board(board)
            print(f"Player {current_player} wins!")
            break
        elif is_board_full(board):
            print_board(board)
            print("It's a draw!")
            break

        current_player = PLAYER_O if current_player == PLAYER_X else PLAYER_X

# Start the game
play_game()
